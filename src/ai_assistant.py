import openai
import streamlit as st
import pandas as pd

# Set up the OpenAI client with your secret key
try:
    openai.api_key = st.secrets["OPENAI_API_KEY"]
except FileNotFoundError:
    st.error("Secrets file not found. Please create .streamlit/secrets.toml")
    st.stop()


def get_ai_insight(question, student_rank_adv, student_rank_main, ambitious_df, safe_df, backup_df):
    """
    Sends a query and context to OpenAI and returns the AI's response.
    """
    # --- The Briefing Sheet for the AI ---
    # We need to give the AI all the context it needs to answer wisely.
    # This is the most important part!

    # Convert the user's results dataframes into a clean string format
    ambitious_str = ambitious_df[['Institute', 'Academic Program Name', 'Predicted_Range']].to_string(index=False)
    safe_str = safe_df[['Institute', 'Academic Program Name', 'Predicted_Range']].to_string(index=False)
    backup_str = backup_df[['Institute', 'Academic Program Name', 'Predicted_Range']].to_string(index=False)

    system_prompt = """
    You are a friendly and expert JEE college counseling assistant.
    Your role is to provide clear, strategic advice to students based on their rank and the predicted college list they provide.
    Analyze the data given to you and answer the user's question concisely.
    Always be encouraging and helpful.
    """

    user_context_prompt = f"""
    Here is my situation:
    - My JEE Advanced Rank is: {student_rank_adv if student_rank_adv else 'Not provided'}
    - My JEE Main Rank is: {student_rank_main}

    Here are the results generated by the prediction tool:

    == AMBITIOUS CHOICES ==
    {ambitious_str}

    == SAFE CHOICES ==
    {safe_str}

    == BACKUP CHOICES ==
    {backup_str}

    Based on all of this information, please answer my following question.
    My Question: "{question}"
    """

    # --- Asking the AI ---
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo", # A fast and cost-effective model
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_context_prompt}
            ],
            max_tokens=250, # Limit the length of the response
            temperature=0.5 # A value between 0 and 1. Lower is more deterministic, higher is more creative.
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"An error occurred with the AI assistant: {e}"
