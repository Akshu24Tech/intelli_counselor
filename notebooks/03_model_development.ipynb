{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model-ready data loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Opening Rank</th>\n",
       "      <th>Closing Rank</th>\n",
       "      <th>Is_Female_Only</th>\n",
       "      <th>Institute_encoded</th>\n",
       "      <th>Academic Program Name_encoded</th>\n",
       "      <th>Quota_encoded</th>\n",
       "      <th>Seat Type_encoded</th>\n",
       "      <th>Institute_Type_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>20319</td>\n",
       "      <td>20319</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>15903</td>\n",
       "      <td>17411</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>54981</td>\n",
       "      <td>56345</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>44634</td>\n",
       "      <td>57812</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>2247</td>\n",
       "      <td>2247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Opening Rank  Closing Rank  Is_Female_Only  Institute_encoded  \\\n",
       "0  2018         20319         20319               1                  0   \n",
       "1  2018         15903         17411               0                  0   \n",
       "2  2018         54981         56345               1                  0   \n",
       "3  2018         44634         57812               0                  0   \n",
       "4  2018          2247          2247               0                  0   \n",
       "\n",
       "   Academic Program Name_encoded  Quota_encoded  Seat Type_encoded  \\\n",
       "0                              3              0                  2   \n",
       "1                              3              0                  2   \n",
       "2                              3              0                  4   \n",
       "3                              3              0                  4   \n",
       "4                              3              0                  5   \n",
       "\n",
       "   Institute_Type_encoded  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define file path\n",
    "PROCESSED_DATA_PATH = '../data/processed/'\n",
    "PREPROCESSED_DATA_FILE = os.path.join(PROCESSED_DATA_PATH, 'preprocessed_data.csv')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(PREPROCESSED_DATA_FILE)\n",
    "\n",
    "print(\"âœ… Model-ready data loaded successfully.\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "# X contains all our clues. We drop the ranks themselves.\n",
    "X = df.drop(['Opening Rank', 'Closing Rank'], axis=1)\n",
    "# y is what we want to predict.\n",
    "y = df['Opening Rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train-Test Split ---\n",
    "# We'll train the model on data up to 2024 and test it on 2025 data.\n",
    "# This simulates a real-world scenario where we predict for a future year.\n",
    "X_train = X[X['Year'] < 2024]\n",
    "y_train = y[X['Year'] < 2024]\n",
    "\n",
    "X_test = X[X['Year'] == 2024]\n",
    "y_test = y[X['Year'] == 2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (54358, 7)\n",
      "Testing data shape:  (11462, 7)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape:  {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Training the LightGBM model...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 54358, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 3723.500000\n",
      "âœ… Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LightGBM Regressor model\n",
    "# These parameters are a good starting point.\n",
    "lgbm = lgb.LGBMRegressor(\n",
    "    objective='regression_l1', # Use L1 loss, which is robust for this kind of data\n",
    "    n_estimators=1000,         # Number of \"decision trees\" to build\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    max_depth=-1,\n",
    "    random_state=42,           # For reproducible results\n",
    "    n_jobs=-1                  # Use all available CPU cores\n",
    ")\n",
    "\n",
    "# Train the model!\n",
    "print(\"ðŸš€ Training the LightGBM model...\")\n",
    "lgbm.fit(X_train, y_train)\n",
    "print(\"âœ… Model training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Performance on 2025 Data ---\n",
      "Mean Absolute Error (MAE): 4348.61\n",
      "R-squared (RÂ²): 0.61\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data (year 2025)\n",
    "predictions = lgbm.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(f\"--- Model Performance on 2025 Data ---\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R-squared (RÂ²): {r2:.2f}\")\n",
    "\n",
    "# MAE: This means our model's predictions are, on average, off by about {mae:.0f} ranks.\n",
    "# RÂ²: Our model can explain about {r2:.0%} of the variation in the closing ranks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a scatter plot of actual vs. predicted ranks\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mscatterplot(x\u001b[38;5;241m=\u001b[39my_test, y\u001b[38;5;241m=\u001b[39mpredictions, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot([\u001b[38;5;241m0\u001b[39m, y_test\u001b[38;5;241m.\u001b[39mmax()], [\u001b[38;5;241m0\u001b[39m, y_test\u001b[38;5;241m.\u001b[39mmax()], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m, lw\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# The perfect prediction line\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual vs. Predicted Closing Ranks for 2025\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scatter plot of actual vs. predicted ranks\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x=y_test, y=predictions, alpha=0.3)\n",
    "plt.plot([0, y_test.max()], [0, y_test.max()], color='red', linestyle='--', lw=2) # The perfect prediction line\n",
    "plt.title('Actual vs. Predicted Closing Ranks for 2025', fontsize=16)\n",
    "plt.xlabel('Actual Closing Rank', fontsize=12)\n",
    "plt.ylabel('Predicted Closing Rank', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Model saved successfully to '../models/opening_rank_model.joblib'\n"
     ]
    }
   ],
   "source": [
    "# Define the path to save the model\n",
    "MODELS_DIR = '../models/'\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.makedirs(MODELS_DIR)\n",
    "\n",
    "MODEL_PATH = os.path.join(MODELS_DIR, 'opening_rank_model.joblib')\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(lgbm, MODEL_PATH)\n",
    "\n",
    "print(f\"ðŸŽ‰ Model saved successfully to '{MODEL_PATH}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
